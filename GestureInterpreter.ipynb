{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_x = []\n",
    "all_data_y = []\n",
    "\n",
    "def parseToArray(fileName):\n",
    "  file = open(fileName,\"r\", errors=\"replace\")\n",
    "  data_label = os.path.splitext(fileName)[0].split('/')[-1]\n",
    "  content = file.read()\n",
    "  samples = content.split(\"---\")\n",
    "  data_x = []\n",
    "  for s in samples:\n",
    "    X = []\n",
    "    labels = s.strip().split('\\n')\n",
    "    for l in labels:\n",
    "      for f in re.sub(\"[\\s]\", \"\",  l).split(','):\n",
    "        X.append(int(f))\n",
    "    data_x.append(X)\n",
    "  data_y = [data_label] * len(data_x)\n",
    "  return data_x, data_y\n",
    "basedir = \"./data/\"\n",
    "files  = [f for f in os.listdir(basedir) if os.path.isfile(os.path.join(basedir, f))]\n",
    "\n",
    "for f in files:\n",
    "  data_x,  data_y = parseToArray(basedir + f)\n",
    "  all_data_x.extend(data_x)\n",
    "  all_data_y.extend(data_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(len(all_data_x)):\n",
    "  d = []\n",
    "  d.extend(all_data_x[i])\n",
    "  d.append(all_data_y[i])\n",
    "  data.append(d)\n",
    "\n",
    "data = sk.utils.shuffle(data)\n",
    "n = len(data)\n",
    "\n",
    "training_data = data[:int(n*0.8)]\n",
    "training_data_x = [a[:-1] for a in training_data]\n",
    "training_data_y = [a[-1] for a in training_data]\n",
    "\n",
    "training_data_x = np.asarray(training_data_x)\n",
    "training_data_y = np.asarray(training_data_y)\n",
    "\n",
    "testing_data = data[int(n*0.8):]\n",
    "testing_data_x = [a[:-1] for a in testing_data]\n",
    "testing_data_y = [a[-1] for a in testing_data]\n",
    "\n",
    "testing_data_x = np.asarray(testing_data_x)\n",
    "testing_data_y = np.asarray(testing_data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr', solver='liblinear')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='ovr',solver=\"liblinear\")\n",
    "\n",
    "model.fit(training_data_x, training_data_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    backward       0.90      0.86      0.88        21\n",
      "     forward       0.88      0.95      0.91        22\n",
      "  play-pause       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.91        56\n",
      "   macro avg       0.92      0.91      0.92        56\n",
      "weighted avg       0.91      0.91      0.91        56\n",
      "\n",
      "0.9107142857142857\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(testing_data_x)\n",
    "print(len(training_data_x))\n",
    "print(sk.metrics.classification_report(testing_data_y,y_pred))\n",
    "print(sk.metrics.accuracy_score(testing_data_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'final_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load The Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestureInterpreter = pickle.load(open('final_model.sav', 'rb'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f8db473d6762dfb6f9dcd7989df9714501dfc9335e8a68c24282034a9bd8d9b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
